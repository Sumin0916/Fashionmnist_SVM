{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사용할 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 불러오기\n",
    "import pickle\n",
    "with open('../models/svm_aug', 'rb') as f:\n",
    "    model_load = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hog Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28)\n",
      "(10000, 6084)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sykim/anaconda3/envs/ml/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but PCA was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 6084 features, but PCA is expecting 784 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/sykim/Desktop/2023-2/ML/Project/codes/test_result.ipynb Cell 4\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sykim/Desktop/2023-2/ML/Project/codes/test_result.ipynb#X10sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m public_hog \u001b[39m=\u001b[39m public_hog\u001b[39m/\u001b[39m\u001b[39m255.0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sykim/Desktop/2023-2/ML/Project/codes/test_result.ipynb#X10sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m## for test ##\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sykim/Desktop/2023-2/ML/Project/codes/test_result.ipynb#X10sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sykim/Desktop/2023-2/ML/Project/codes/test_result.ipynb#X10sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39m# pca = PCA(n_components=250)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sykim/Desktop/2023-2/ML/Project/codes/test_result.ipynb#X10sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sykim/Desktop/2023-2/ML/Project/codes/test_result.ipynb#X10sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39m# public_hog_pca = pd.DataFrame(public_hog_pca)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/sykim/Desktop/2023-2/ML/Project/codes/test_result.ipynb#X10sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m public_pred \u001b[39m=\u001b[39m model_load\u001b[39m.\u001b[39;49mpredict(public_hog)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sykim/Desktop/2023-2/ML/Project/codes/test_result.ipynb#X10sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m f\u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m../testResults/testResult_public_hog.txt\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mw+\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sykim/Desktop/2023-2/ML/Project/codes/test_result.ipynb#X10sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39mfor\u001b[39;00m idx, y \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(public_pred):\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.9/site-packages/sklearn/pipeline.py:514\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    512\u001b[0m Xt \u001b[39m=\u001b[39m X\n\u001b[1;32m    513\u001b[0m \u001b[39mfor\u001b[39;00m _, name, transform \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter(with_final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 514\u001b[0m     Xt \u001b[39m=\u001b[39m transform\u001b[39m.\u001b[39;49mtransform(Xt)\n\u001b[1;32m    515\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mpredict(Xt, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpredict_params)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.9/site-packages/sklearn/utils/_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    156\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 157\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    158\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    159\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    160\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[1;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    162\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    163\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.9/site-packages/sklearn/decomposition/_base.py:121\u001b[0m, in \u001b[0;36m_BasePCA.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Apply dimensionality reduction to X.\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \n\u001b[1;32m    104\u001b[0m \u001b[39mX is projected on the first principal components previously extracted\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39m    is the number of samples and `n_components` is the number of the components.\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    119\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> 121\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, dtype\u001b[39m=\u001b[39;49m[np\u001b[39m.\u001b[39;49mfloat64, np\u001b[39m.\u001b[39;49mfloat32], reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    122\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmean_ \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    123\u001b[0m     X \u001b[39m=\u001b[39m X \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmean_\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.9/site-packages/sklearn/base.py:626\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    623\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m--> 626\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_n_features(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[1;32m    628\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.9/site-packages/sklearn/base.py:415\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    412\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 415\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    416\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    417\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    418\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 6084 features, but PCA is expecting 784 features as input."
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from skimage.feature import hog\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def apply_hog(images):\n",
    "    result = []\n",
    "    for image in images:\n",
    "        hog_features = hog(image, orientations=9, pixels_per_cell=(2, 2),\n",
    "                        cells_per_block=(2, 2), block_norm='L2-Hys')\n",
    "        result.append(hog_features)\n",
    "    return result\n",
    "\n",
    "public_set = []\n",
    "dir_name = '../public_test_dataset/data/'\n",
    "lists = sorted(os.listdir(dir_name))\n",
    "for idx, img in enumerate(lists):\n",
    "    image_gray = cv2.imread(dir_name+img, cv2.IMREAD_GRAYSCALE)\n",
    "    # image = apply_hog(image_gray)\n",
    "    image = np.array(image_gray.reshape((784,)))\n",
    "    # image = np.array(Image.open(dir_name+img)).reshape((784,))\n",
    "    image = image.tolist()\n",
    "    public_set.append(image)\n",
    "public_set = np.array(public_set)\n",
    "public_set = public_set.reshape(-1, 28, 28)\n",
    "print(public_set.shape)\n",
    "# private = pd.DataFrame(private_set)\n",
    "\n",
    "public_hog = apply_hog(public_set)\n",
    "public_hog = np.array(public_hog)\n",
    "print(public_hog.shape)\n",
    "# private.columns = model_load.feature_names_in_\n",
    "public_hog = public_hog/255.0\n",
    "## for test ##\n",
    "\n",
    "# pca = PCA(n_components=250)\n",
    "# pca.fit(public_hog)\n",
    "# public_hog_pca = pca.transform(public_hog)\n",
    "# y_test_pca = pca.transform(X_test_hog)\n",
    "\n",
    "# public_hog_pca = pd.DataFrame(public_hog_pca)\n",
    "public_pred = model_load.predict(public_hog)\n",
    "\n",
    "f= open(\"../testResults/testResult_public_hog.txt\",\"w+\")\n",
    "for idx, y in enumerate(public_pred):\n",
    "    img_num = str(idx).zfill(5)\n",
    "    f.write(img_num + \" \" + str(y) + \"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Public Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "testset = []\n",
    "dir_name = '../public_test_dataset/data/'\n",
    "lists = sorted(os.listdir(dir_name))\n",
    "for idx, img in enumerate(lists):\n",
    "    image_gray = cv2.imread(dir_name+img, cv2.IMREAD_GRAYSCALE)\n",
    "    image = np.array(image_gray.reshape((784,)))\n",
    "    # image = np.array(Image.open(dir_name+img)).reshape((784,))\n",
    "    image = image.tolist()\n",
    "    testset.append(image)\n",
    "testset = np.array(testset)\n",
    "test = pd.DataFrame(testset)\n",
    "test.columns = model_load.feature_names_in_\n",
    "test = test/255.0\n",
    "pred = model_load.predict(test)\n",
    "f= open(\"../testResults/testResult_public_aug.txt\",\"w+\")\n",
    "for idx, y in enumerate(pred):\n",
    "    num_str = str(idx).zfill(5)\n",
    "    f.write(num_str + \" \" + str(int(y)) + \"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Private Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "private_set = []\n",
    "dir_name = '../private_test_dataset/data/'\n",
    "lists = sorted(os.listdir(dir_name))\n",
    "for idx, img in enumerate(lists):\n",
    "    image_gray = cv2.imread(dir_name+img, cv2.IMREAD_GRAYSCALE)\n",
    "    image = np.array(image_gray.reshape((784,)))\n",
    "    # image = np.array(Image.open(dir_name+img)).reshape((784,))\n",
    "    image = image.tolist()\n",
    "    private_set.append(image)\n",
    "private_set = np.array(private_set)\n",
    "private = pd.DataFrame(private_set)\n",
    "private.columns = model_load.feature_names_in_\n",
    "private = private/255.0\n",
    "private_pred = model_load.predict(private)\n",
    "f= open(\"../testResults/testResult_private_aug.txt\",\"w+\")\n",
    "for idx, y in enumerate(private_pred):\n",
    "    img_num = str(idx).zfill(5)\n",
    "    f.write(img_num + \" \" + str(int(y)) + \"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
