{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightgbm import LGBMClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import ensemble\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../fashionmnist/120000_augmented.csv')\n",
    "train.isnull().any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "testset = []\n",
    "dir_name = '../public_test_dataset/data/'\n",
    "lists = sorted(os.listdir(dir_name))\n",
    "for idx, img in enumerate(lists):\n",
    "    image_gray = cv2.imread(dir_name+img, cv2.IMREAD_GRAYSCALE)\n",
    "    image = np.array(image_gray.reshape((784,)))\n",
    "    # image = np.array(Image.open(dir_name+img)).reshape((784,))\n",
    "    image = image.tolist()\n",
    "    testset.append(image)\n",
    "testset = np.array(testset)\n",
    "test = pd.DataFrame(testset)\n",
    "test = test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "private_set = []\n",
    "dir_name = '../private_test_dataset/data/'\n",
    "lists = sorted(os.listdir(dir_name))\n",
    "for idx, img in enumerate(lists):\n",
    "    image_gray = cv2.imread(dir_name+img, cv2.IMREAD_GRAYSCALE)\n",
    "    image = np.array(image_gray.reshape((784,)))\n",
    "    # image = np.array(Image.open(dir_name+img)).reshape((784,))\n",
    "    image = image.tolist()\n",
    "    private_set.append(image)\n",
    "private_set = np.array(private_set)\n",
    "private = pd.DataFrame(private_set)\n",
    "private = private/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120000, 785) \n",
      " (10000, 784) \n",
      " (15000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape,'\\n', test.shape,'\\n',private.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = train.copy()\n",
    "df_test = test.copy()\n",
    "df_private = private.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= df_train.drop(['label'],axis = 1)\n",
    "y_train = df_train['label']\n",
    "X_test = df_test\n",
    "X_private = df_private\n",
    "# y_test = df_test.drop(['label'],axis = 1)\n",
    "# y_label = df_test['label']\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_private = X_private.astype('float32')\n",
    "X_train /= 255.0\n",
    "# y_test /=255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train과 X_label을 하나의 데이터 프레임으로 합침\n",
    "df_train = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "# 데이터 프레임을 섞음\n",
    "df_train = df_train.sample(frac=1, random_state=42)\n",
    "\n",
    "# 섞인 데이터 프레임에서 훈련 데이터와 레이블을 다시 분리\n",
    "X_train = df_train.drop(['label'], axis=1)\n",
    "y_train = df_train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import hog\n",
    "def apply_hog(images):\n",
    "    images = np.array(images)\n",
    "    images = images.reshape(-1, 28, 28)\n",
    "    result = []\n",
    "    for image in images:\n",
    "        hog_features = hog(image, orientations=9, pixels_per_cell=(4, 4),\n",
    "                        cells_per_block=(2, 2), block_norm='L2')\n",
    "        result.append(hog_features)\n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120000, 784)\n",
      "(10000, 784)\n",
      "(15000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_private.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ens = np.array(X_train)\n",
    "X_test_ens = np.array(X_test)\n",
    "X_private_ens = np.array(X_private)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = LGBMClassifier(\n",
    "    n_estimators=839,\n",
    "    num_leaves=4,\n",
    "    min_child_samples=6,\n",
    "    learning_rate=0.17305095027775025,\n",
    "    max_bin=1024,  # log_max_bin을 10으로 설정했으므로, max_bin은 2^10인 1024가 됩니다.\n",
    "    colsample_bytree=0.8717502271722275,\n",
    "    reg_alpha=0.036114468962103394,\n",
    "    reg_lambda=0.23607505416113697,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_lgbm = PCA(n_components=400, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이프라인 적용\n",
    "pipe_lgbm = Pipeline([\n",
    "    ('pca_lgbm', pca_lgbm),\n",
    "    ('lgbm', lgbm)\n",
    "], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .......... (step 1 of 2) Processing pca_lgbm, total=  10.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.216026 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 409600\n",
      "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 400\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[Pipeline] .............. (step 2 of 2) Processing lgbm, total= 1.9min\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;pca_lgbm&#x27;, PCA(n_components=400, random_state=43)),\n",
       "                (&#x27;lgbm&#x27;,\n",
       "                 LGBMClassifier(colsample_bytree=0.8717502271722275,\n",
       "                                learning_rate=0.17305095027775025, max_bin=1024,\n",
       "                                min_child_samples=6, n_estimators=839,\n",
       "                                num_leaves=4, reg_alpha=0.036114468962103394,\n",
       "                                reg_lambda=0.23607505416113697))],\n",
       "         verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;pca_lgbm&#x27;, PCA(n_components=400, random_state=43)),\n",
       "                (&#x27;lgbm&#x27;,\n",
       "                 LGBMClassifier(colsample_bytree=0.8717502271722275,\n",
       "                                learning_rate=0.17305095027775025, max_bin=1024,\n",
       "                                min_child_samples=6, n_estimators=839,\n",
       "                                num_leaves=4, reg_alpha=0.036114468962103394,\n",
       "                                reg_lambda=0.23607505416113697))],\n",
       "         verbose=True)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(n_components=400, random_state=43)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(colsample_bytree=0.8717502271722275,\n",
       "               learning_rate=0.17305095027775025, max_bin=1024,\n",
       "               min_child_samples=6, n_estimators=839, num_leaves=4,\n",
       "               reg_alpha=0.036114468962103394, reg_lambda=0.23607505416113697)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('pca_lgbm', PCA(n_components=400, random_state=43)),\n",
       "                ('lgbm',\n",
       "                 LGBMClassifier(colsample_bytree=0.8717502271722275,\n",
       "                                learning_rate=0.17305095027775025, max_bin=1024,\n",
       "                                min_child_samples=6, n_estimators=839,\n",
       "                                num_leaves=4, reg_alpha=0.036114468962103394,\n",
       "                                reg_lambda=0.23607505416113697))],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_lgbm.fit(X_train_ens, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only XGB mAP for public test\n",
    "pred_lgbm = pipe_lgbm.predict(X_test_ens)\n",
    "\n",
    "f= open(\"../testResults/testResult_public_lgbm.txt\",\"w+\")\n",
    "for idx, y in enumerate(pred_lgbm):\n",
    "    num_str = str(idx).zfill(5)\n",
    "    f.write(num_str + \" \" + str(int(y)) + \"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Class         | AP            |\n",
      "|---------------|---------------|\n",
      "| T-shirt/top   | 0.66          |\n",
      "| Trouser       | 0.98          |\n",
      "| Pullover      | 0.64          |\n",
      "| Dress         | 0.79          |\n",
      "| Coat          | 0.68          |\n",
      "| Sandal        | 0.91          |\n",
      "| Shirt         | 0.50          |\n",
      "| Sneaker       | 0.85          |\n",
      "| Bag           | 0.92          |\n",
      "| Ankle boot    | 0.89          |\n",
      "| mAP           | 0.78          |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from sklearn.metrics import auc\n",
    "from collections import Counter\n",
    "\n",
    "# testResult_path = sys.argv[1]\n",
    "# label_path = sys.argv[2]\n",
    "\n",
    "testResult_path = '../testResults/testResult_public_lgbm.txt'\n",
    "label_path = '../mAP/label.txt'\n",
    "\n",
    "# pred에 해당하는 testResult.txt 파일 읽어오는 부분입니다.\n",
    "with open(testResult_path, 'r') as file1:\n",
    "    preds = file1.readlines()\n",
    "\n",
    "# 정답에 해당하는 label.txt 파일 읽어오는 부분입니다.\n",
    "with open(label_path, 'r') as file2:\n",
    "    labels = file2.readlines()\n",
    "    \n",
    "\n",
    "# pred와 label의 클래스값만 리스트로 변환하는 부분입니다.\n",
    "p = np.array([pred.strip().split()[1] for pred in preds])\n",
    "l = np.array([label.strip().split()[1] for label in labels])\n",
    "\n",
    "# pred의 클래스 개수를 count하는 부분입니다.\n",
    "predict_label_count_dict = Counter(p)\n",
    "predict_label_count_dict = dict(sorted(predict_label_count_dict.items()))\n",
    "\n",
    "## mAP 계산하는 부분입니다.\n",
    "AP = []\n",
    "num_class = 10\n",
    "\n",
    "# 모든 클래스에 대해 반복\n",
    "for c, freq in predict_label_count_dict.items() :\n",
    "    TP = 0\n",
    "    FN = 0\n",
    "\n",
    "    temp_precision = []\n",
    "    temp_recall = []\n",
    "    \n",
    "    for i in range(len(p)):\n",
    "        # TP, FN 계산\n",
    "        if l[i] == c and p[i] == c :\n",
    "            TP += 1\n",
    "        elif l[i] != c and p[i] == c :\n",
    "            FN += 1\n",
    "        \n",
    "        # preciison, recall 계산            \n",
    "        if TP+FN != 0: \n",
    "            temp_precision.append(TP/(TP+FN))\n",
    "            temp_recall.append(TP/freq)\n",
    "\n",
    "    # AP 배열에 클래스 각각의 AP value 저장\n",
    "    # auc : preciison-recall curve의 면적 구해줌\n",
    "    # print(\"TP :\", TP)\n",
    "    # print(\"FN :\", FN)\n",
    "    # print(temp_precision)\n",
    "    # print(temp_recall)\n",
    "    AP.append(auc(temp_recall, temp_precision))\n",
    "\n",
    "mAP = sum(AP) / num_class\n",
    "\n",
    "# 각각의 클래스에 대한 AP와 mAP의 Table 출력 부분입니다.\n",
    "class_name = ['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle boot']\n",
    "table = \"| {:<13} | {:<13} |\\n\".format(\"Class\", \"AP\") + \"|---------------|---------------|\\n\"\n",
    "\n",
    "for c_name, ap in zip(class_name, AP):\n",
    "    table += \"| {:<13} | {:<13.2f} |\\n\".format(c_name, ap)\n",
    "\n",
    "table += \"| {:<13} | {:<13.2f} |\\n\".format(\"mAP\", mAP)\n",
    "lgbm_test_mAP = mAP\n",
    "print(table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(\n",
    "    objective=\"multi:softmax\", # OR objective='multi:softmax', num_class=10\n",
    "    n_estimators=600, \n",
    "    n_jobs=-1, \n",
    "    learning_rate=0.08, \n",
    "    max_depth= 6,\n",
    "    reg_lambda =2,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    eval_metric= \"merror\",\n",
    "    reg_alpha= 8,\n",
    "    num_class=10\n",
    "    )\n",
    "# xgb = XGBClassifier(\n",
    "#     n_estimators=500, \n",
    "#     n_jobs=-1, \n",
    "#     learning_rate=0.5, \n",
    "#     max_depth= 5, \n",
    "#     min_child_weight= 1, \n",
    "#     reg_lambda =20, \n",
    "#     seed=0\n",
    "#     )\n",
    "# xgb = XGBClassifier(use_label_encoder=False,objective=\"multi:softmax\",eval_metric=\"merror\",n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_xgb = PCA(n_components=500, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이프라인 적용\n",
    "pipe_xgb = Pipeline([\n",
    "    ('pca_xgb', pca_xgb),\n",
    "    ('xgb', xgb)\n",
    "], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........... (step 1 of 2) Processing pca_xgb, total=  10.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing xgb, total= 7.0min\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;pca_xgb&#x27;, PCA(n_components=500, random_state=43)),\n",
       "                (&#x27;xgb&#x27;,\n",
       "                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                               colsample_bylevel=None, colsample_bynode=None,\n",
       "                               colsample_bytree=0.8, device=None,\n",
       "                               early_stopping_rounds=None,\n",
       "                               enable_categorical=False, eval_metric=&#x27;merror&#x27;,\n",
       "                               feature_types=None, gamma=None, grow_policy=None,\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=0.08,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=6, max_leaves=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               monotone_constraints=None, multi_strategy=None,\n",
       "                               n_estimators=600, n_jobs=-1, num_class=10,\n",
       "                               num_parallel_tree=None, ...))],\n",
       "         verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;pca_xgb&#x27;, PCA(n_components=500, random_state=43)),\n",
       "                (&#x27;xgb&#x27;,\n",
       "                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                               colsample_bylevel=None, colsample_bynode=None,\n",
       "                               colsample_bytree=0.8, device=None,\n",
       "                               early_stopping_rounds=None,\n",
       "                               enable_categorical=False, eval_metric=&#x27;merror&#x27;,\n",
       "                               feature_types=None, gamma=None, grow_policy=None,\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=0.08,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=6, max_leaves=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               monotone_constraints=None, multi_strategy=None,\n",
       "                               n_estimators=600, n_jobs=-1, num_class=10,\n",
       "                               num_parallel_tree=None, ...))],\n",
       "         verbose=True)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(n_components=500, random_state=43)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;merror&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.08, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=600,\n",
       "              n_jobs=-1, num_class=10, num_parallel_tree=None, ...)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('pca_xgb', PCA(n_components=500, random_state=43)),\n",
       "                ('xgb',\n",
       "                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                               colsample_bylevel=None, colsample_bynode=None,\n",
       "                               colsample_bytree=0.8, device=None,\n",
       "                               early_stopping_rounds=None,\n",
       "                               enable_categorical=False, eval_metric='merror',\n",
       "                               feature_types=None, gamma=None, grow_policy=None,\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=0.08,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=6, max_leaves=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               monotone_constraints=None, multi_strategy=None,\n",
       "                               n_estimators=600, n_jobs=-1, num_class=10,\n",
       "                               num_parallel_tree=None, ...))],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_xgb.fit(X_train_ens, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only XGB mAP for public test\n",
    "pred_xgb = pipe_xgb.predict(X_test_ens)\n",
    "\n",
    "f= open(\"../testResults/testResult_public_xgb.txt\",\"w+\")\n",
    "for idx, y in enumerate(pred_xgb):\n",
    "    num_str = str(idx).zfill(5)\n",
    "    f.write(num_str + \" \" + str(int(y)) + \"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Class         | AP            |\n",
      "|---------------|---------------|\n",
      "| T-shirt/top   | 0.68          |\n",
      "| Trouser       | 0.96          |\n",
      "| Pullover      | 0.68          |\n",
      "| Dress         | 0.79          |\n",
      "| Coat          | 0.68          |\n",
      "| Sandal        | 0.91          |\n",
      "| Shirt         | 0.55          |\n",
      "| Sneaker       | 0.86          |\n",
      "| Bag           | 0.93          |\n",
      "| Ankle boot    | 0.88          |\n",
      "| mAP           | 0.79          |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from sklearn.metrics import auc\n",
    "from collections import Counter\n",
    "\n",
    "# testResult_path = sys.argv[1]\n",
    "# label_path = sys.argv[2]\n",
    "\n",
    "testResult_path = '../testResults/testResult_public_xgb.txt'\n",
    "label_path = '../mAP/label.txt'\n",
    "\n",
    "# pred에 해당하는 testResult.txt 파일 읽어오는 부분입니다.\n",
    "with open(testResult_path, 'r') as file1:\n",
    "    preds = file1.readlines()\n",
    "\n",
    "# 정답에 해당하는 label.txt 파일 읽어오는 부분입니다.\n",
    "with open(label_path, 'r') as file2:\n",
    "    labels = file2.readlines()\n",
    "    \n",
    "\n",
    "# pred와 label의 클래스값만 리스트로 변환하는 부분입니다.\n",
    "p = np.array([pred.strip().split()[1] for pred in preds])\n",
    "l = np.array([label.strip().split()[1] for label in labels])\n",
    "\n",
    "# pred의 클래스 개수를 count하는 부분입니다.\n",
    "predict_label_count_dict = Counter(p)\n",
    "predict_label_count_dict = dict(sorted(predict_label_count_dict.items()))\n",
    "\n",
    "## mAP 계산하는 부분입니다.\n",
    "AP = []\n",
    "num_class = 10\n",
    "\n",
    "# 모든 클래스에 대해 반복\n",
    "for c, freq in predict_label_count_dict.items() :\n",
    "    TP = 0\n",
    "    FN = 0\n",
    "\n",
    "    temp_precision = []\n",
    "    temp_recall = []\n",
    "    \n",
    "    for i in range(len(p)):\n",
    "        # TP, FN 계산\n",
    "        if l[i] == c and p[i] == c :\n",
    "            TP += 1\n",
    "        elif l[i] != c and p[i] == c :\n",
    "            FN += 1\n",
    "        \n",
    "        # preciison, recall 계산            \n",
    "        if TP+FN != 0: \n",
    "            temp_precision.append(TP/(TP+FN))\n",
    "            temp_recall.append(TP/freq)\n",
    "\n",
    "    # AP 배열에 클래스 각각의 AP value 저장\n",
    "    # auc : preciison-recall curve의 면적 구해줌\n",
    "    # print(\"TP :\", TP)\n",
    "    # print(\"FN :\", FN)\n",
    "    # print(temp_precision)\n",
    "    # print(temp_recall)\n",
    "    AP.append(auc(temp_recall, temp_precision))\n",
    "\n",
    "mAP = sum(AP) / num_class\n",
    "\n",
    "# 각각의 클래스에 대한 AP와 mAP의 Table 출력 부분입니다.\n",
    "class_name = ['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle boot']\n",
    "table = \"| {:<13} | {:<13} |\\n\".format(\"Class\", \"AP\") + \"|---------------|---------------|\\n\"\n",
    "\n",
    "for c_name, ap in zip(class_name, AP):\n",
    "    table += \"| {:<13} | {:<13.2f} |\\n\".format(c_name, ap)\n",
    "\n",
    "table += \"| {:<13} | {:<13.2f} |\\n\".format(\"mAP\", mAP)\n",
    "xgb_test_mAP = mAP\n",
    "print(table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM + HOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=250, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_c = 8\n",
    "svc = SVC(gamma='scale',kernel='rbf',C=optimal_c, random_state=43, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "pipe_svm = Pipeline([\n",
    "    ('hog', FunctionTransformer(apply_hog)),\n",
    "    ('pca', pca),\n",
    "    ('svm', svc)\n",
    "], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 1 of 3) Processing hog, total=  28.0s\n",
      "[Pipeline] ............... (step 2 of 3) Processing pca, total=   8.5s\n",
      "[Pipeline] ............... (step 3 of 3) Processing svm, total=12.7min\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;hog&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function apply_hog at 0x15e09f8b0&gt;)),\n",
       "                (&#x27;pca&#x27;, PCA(n_components=250, random_state=43)),\n",
       "                (&#x27;svm&#x27;, SVC(C=8, random_state=43))],\n",
       "         verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;hog&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function apply_hog at 0x15e09f8b0&gt;)),\n",
       "                (&#x27;pca&#x27;, PCA(n_components=250, random_state=43)),\n",
       "                (&#x27;svm&#x27;, SVC(C=8, random_state=43))],\n",
       "         verbose=True)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function apply_hog at 0x15e09f8b0&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(n_components=250, random_state=43)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=8, random_state=43)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('hog',\n",
       "                 FunctionTransformer(func=<function apply_hog at 0x15e09f8b0>)),\n",
       "                ('pca', PCA(n_components=250, random_state=43)),\n",
       "                ('svm', SVC(C=8, random_state=43))],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_svm.fit(X_train_ens, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only XGB mAP for public test\n",
    "pred_svm = pipe_svm.predict(X_test_ens)\n",
    "\n",
    "f= open(\"../testResults/testResult_public_svm.txt\",\"w+\")\n",
    "for idx, y in enumerate(pred_svm):\n",
    "    num_str = str(idx).zfill(5)\n",
    "    f.write(num_str + \" \" + str(int(y)) + \"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Class         | AP            |\n",
      "|---------------|---------------|\n",
      "| T-shirt/top   | 0.76          |\n",
      "| Trouser       | 0.98          |\n",
      "| Pullover      | 0.81          |\n",
      "| Dress         | 0.84          |\n",
      "| Coat          | 0.74          |\n",
      "| Sandal        | 0.97          |\n",
      "| Shirt         | 0.60          |\n",
      "| Sneaker       | 0.90          |\n",
      "| Bag           | 0.98          |\n",
      "| Ankle boot    | 0.95          |\n",
      "| mAP           | 0.85          |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from sklearn.metrics import auc\n",
    "from collections import Counter\n",
    "\n",
    "# testResult_path = sys.argv[1]\n",
    "# label_path = sys.argv[2]\n",
    "\n",
    "testResult_path = '../testResults/testResult_public_svm.txt'\n",
    "label_path = '../mAP/label.txt'\n",
    "\n",
    "# pred에 해당하는 testResult.txt 파일 읽어오는 부분입니다.\n",
    "with open(testResult_path, 'r') as file1:\n",
    "    preds = file1.readlines()\n",
    "\n",
    "# 정답에 해당하는 label.txt 파일 읽어오는 부분입니다.\n",
    "with open(label_path, 'r') as file2:\n",
    "    labels = file2.readlines()\n",
    "    \n",
    "\n",
    "# pred와 label의 클래스값만 리스트로 변환하는 부분입니다.\n",
    "p = np.array([pred.strip().split()[1] for pred in preds])\n",
    "l = np.array([label.strip().split()[1] for label in labels])\n",
    "\n",
    "# pred의 클래스 개수를 count하는 부분입니다.\n",
    "predict_label_count_dict = Counter(p)\n",
    "predict_label_count_dict = dict(sorted(predict_label_count_dict.items()))\n",
    "\n",
    "## mAP 계산하는 부분입니다.\n",
    "AP = []\n",
    "num_class = 10\n",
    "\n",
    "# 모든 클래스에 대해 반복\n",
    "for c, freq in predict_label_count_dict.items() :\n",
    "    TP = 0\n",
    "    FN = 0\n",
    "\n",
    "    temp_precision = []\n",
    "    temp_recall = []\n",
    "    \n",
    "    for i in range(len(p)):\n",
    "        # TP, FN 계산\n",
    "        if l[i] == c and p[i] == c :\n",
    "            TP += 1\n",
    "        elif l[i] != c and p[i] == c :\n",
    "            FN += 1\n",
    "        \n",
    "        # preciison, recall 계산            \n",
    "        if TP+FN != 0: \n",
    "            temp_precision.append(TP/(TP+FN))\n",
    "            temp_recall.append(TP/freq)\n",
    "\n",
    "    # AP 배열에 클래스 각각의 AP value 저장\n",
    "    # auc : preciison-recall curve의 면적 구해줌\n",
    "    # print(\"TP :\", TP)\n",
    "    # print(\"FN :\", FN)\n",
    "    # print(temp_precision)\n",
    "    # print(temp_recall)\n",
    "    AP.append(auc(temp_recall, temp_precision))\n",
    "\n",
    "mAP = sum(AP) / num_class\n",
    "\n",
    "# 각각의 클래스에 대한 AP와 mAP의 Table 출력 부분입니다.\n",
    "class_name = ['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle boot']\n",
    "table = \"| {:<13} | {:<13} |\\n\".format(\"Class\", \"AP\") + \"|---------------|---------------|\\n\"\n",
    "\n",
    "for c_name, ap in zip(class_name, AP):\n",
    "    table += \"| {:<13} | {:<13.2f} |\\n\".format(c_name, ap)\n",
    "\n",
    "table += \"| {:<13} | {:<13.2f} |\\n\".format(\"mAP\", mAP)\n",
    "svm_test_mAP = mAP\n",
    "print(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 저장\n",
    "import pickle\n",
    "with open('../models/svm_hog_pipeline', 'wb') as f:\n",
    "    pickle.dump(pipe_svm, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 앙상블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = list()\n",
    "models.append(('xgb', pipe_xgb))\n",
    "models.append(('svm_hog', pipe_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "# define the voting ensemble\n",
    "voting = VotingClassifier(estimators=models, voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting.fit(X_train_ens, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_voting = voting.predict(X_test_ens)\n",
    "f= open(\"../testResults/testResult_public_voting.txt\",\"w+\")\n",
    "for idx, y in enumerate(pred_voting):\n",
    "    num_str = str(idx).zfill(5)\n",
    "    f.write(num_str + \" \" + str(int(y)) + \"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from sklearn.metrics import auc\n",
    "from collections import Counter\n",
    "\n",
    "# testResult_path = sys.argv[1]\n",
    "# label_path = sys.argv[2]\n",
    "\n",
    "testResult_path = '../testResults/testResult_public_voting.txt'\n",
    "label_path = '../mAP/label.txt'\n",
    "\n",
    "# pred에 해당하는 testResult.txt 파일 읽어오는 부분입니다.\n",
    "with open(testResult_path, 'r') as file1:\n",
    "    preds = file1.readlines()\n",
    "\n",
    "# 정답에 해당하는 label.txt 파일 읽어오는 부분입니다.\n",
    "with open(label_path, 'r') as file2:\n",
    "    labels = file2.readlines()\n",
    "    \n",
    "\n",
    "# pred와 label의 클래스값만 리스트로 변환하는 부분입니다.\n",
    "p = np.array([pred.strip().split()[1] for pred in preds])\n",
    "l = np.array([label.strip().split()[1] for label in labels])\n",
    "\n",
    "# pred의 클래스 개수를 count하는 부분입니다.\n",
    "predict_label_count_dict = Counter(p)\n",
    "predict_label_count_dict = dict(sorted(predict_label_count_dict.items()))\n",
    "\n",
    "## mAP 계산하는 부분입니다.\n",
    "AP = []\n",
    "num_class = 10\n",
    "\n",
    "# 모든 클래스에 대해 반복\n",
    "for c, freq in predict_label_count_dict.items() :\n",
    "    TP = 0\n",
    "    FN = 0\n",
    "\n",
    "    temp_precision = []\n",
    "    temp_recall = []\n",
    "    \n",
    "    for i in range(len(p)):\n",
    "        # TP, FN 계산\n",
    "        if l[i] == c and p[i] == c :\n",
    "            TP += 1\n",
    "        elif l[i] != c and p[i] == c :\n",
    "            FN += 1\n",
    "        \n",
    "        # preciison, recall 계산            \n",
    "        if TP+FN != 0: \n",
    "            temp_precision.append(TP/(TP+FN))\n",
    "            temp_recall.append(TP/freq)\n",
    "\n",
    "    # AP 배열에 클래스 각각의 AP value 저장\n",
    "    # auc : preciison-recall curve의 면적 구해줌\n",
    "    # print(\"TP :\", TP)\n",
    "    # print(\"FN :\", FN)\n",
    "    # print(temp_precision)\n",
    "    # print(temp_recall)\n",
    "    AP.append(auc(temp_recall, temp_precision))\n",
    "\n",
    "mAP = sum(AP) / num_class\n",
    "\n",
    "# 각각의 클래스에 대한 AP와 mAP의 Table 출력 부분입니다.\n",
    "class_name = ['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle boot']\n",
    "table = \"| {:<13} | {:<13} |\\n\".format(\"Class\", \"AP\") + \"|---------------|---------------|\\n\"\n",
    "\n",
    "for c_name, ap in zip(class_name, AP):\n",
    "    table += \"| {:<13} | {:<13.2f} |\\n\".format(c_name, ap)\n",
    "\n",
    "table += \"| {:<13} | {:<13.2f} |\\n\".format(\"mAP\", mAP)\n",
    "voting_test_mAP = mAP\n",
    "print(table)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
