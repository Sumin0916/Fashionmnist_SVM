{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "99IcNqG63q2f"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import utils\n",
    "import pandas as pd\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import warnings\n",
    "import os\n",
    "from PIL import Image\n",
    "from skimage.feature import hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "emy5HT1T3q2h"
   },
   "outputs": [],
   "source": [
    "\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../fashionmnist/fashion-mnist_train.csv')\n",
    "augmented_train = train.copy()\n",
    "X_train = augmented_train.drop(['label'],axis = 1)\n",
    "X_label = augmented_train['label']\n",
    "\n",
    "X_train = X_train.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {\n",
    "    \"T-shirt/top\":0,\n",
    "    \"Trouser\":1,\n",
    "    \"Pullover\":2,\n",
    "    \"Dress\":3,\n",
    "    \"Coat\":4,\n",
    "    \"Sandal\":5,\n",
    "    \"Shirt\":6,\n",
    "    \"Sneaker\":7,\n",
    "    \"Bag\":8,\n",
    "    \"Ankle_boot\":9\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원하는 Label number 리스트로 담기\n",
    "is_target = [False for _ in range(10)]\n",
    "target_labels = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle_boot\"] #증강할 옷 종류 담기\n",
    "for label in target_labels:\n",
    "    is_target[label_dict[label]] = True\n",
    "target_res = [[] for _ in range(10)]\n",
    "\n",
    "train_count = X_train.shape[0]\n",
    "for ind in range(train_count):\n",
    "    if is_target[X_label[ind]]:\n",
    "        target_res[X_label[ind]].append(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_train = X_train.values # pandas.DF -> numpy.ARRAY\n",
    "origin_train = origin_train.reshape(-1, 28, 28, 1) # 60000x28x28로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before data shape: (60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "augmented_train = train.copy()\n",
    "# plt.imshow(origin_train[59999], cmap='gray')\n",
    "# plt.axis('off')\n",
    "# plt.show()\n",
    "\n",
    "print(f\"Before data shape: {origin_train.shape}\")\n",
    "image_generator = ImageDataGenerator(\n",
    "            width_shift_range=0.01, # 세로 이동 범위\n",
    "            height_shift_range=0.05,# 가로 이동 범위\n",
    "            dtype=\"int64\",\n",
    "            fill_mode=\"constant\",\n",
    "            cval=0,\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated Augmented shape: (120000, 785)\n",
      "After data shape: (120000, 785)\n"
     ]
    }
   ],
   "source": [
    "sample_size = 300 # 각 label마다 추출할 표본 개수\n",
    "augment_size = 20 # 각 표본별 증강할 개수\n",
    "\n",
    "print(f\"Estimated Augmented shape: ({(sample_size*len(target_labels)*augment_size) + origin_train.shape[0]}, 785)\")\n",
    "\n",
    "for label in target_labels:\n",
    "    abstract_class  = random.sample(target_res[label_dict[label]], sample_size) #옷을 종류별로 sample_size만큼 무작위 선택\n",
    "    labels = [label_dict[label] for _ in range(augment_size)]\n",
    "    for ind in abstract_class:\n",
    "        images = np.array([origin_train[ind] for _ in range(augment_size)])\n",
    "        aug_imgs, aug_labels = image_generator.flow(images, labels, batch_size=augment_size, shuffle=False, seed=1127).next() #save_prefix='augmented', save_to_dir=\"./augment\", \n",
    "        aug_imgs = aug_imgs.reshape(augment_size, 784)\n",
    "        aug_imgs = np.insert(aug_imgs, 0, aug_labels, axis=1)\n",
    "        df_augmented = pd.DataFrame(aug_imgs, columns=augmented_train.columns)\n",
    "        augmented_train = pd.concat([augmented_train, df_augmented], ignore_index=True)\n",
    "\n",
    "augmented_train = augmented_train.fillna(0.0)\n",
    "print(f\"After data shape: {augmented_train.shape}\")\n",
    "augmented_train = utils.shuffle(augmented_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_train.to_csv('./120000_augmented.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XLy3i9aa3q2i",
    "outputId": "5028f112-f62a-450b-b3ac-1f48356b36cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train = pd.read_csv('120000_augmented.csv')\n",
    "train.isnull().any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = []\n",
    "dir_name = '../public_test_dataset/data/'\n",
    "lists = sorted(os.listdir(dir_name))\n",
    "for idx, img in enumerate(lists):\n",
    "    image_gray = cv2.imread(dir_name+img, cv2.IMREAD_GRAYSCALE)\n",
    "    image = np.array(image_gray.reshape((784,)))\n",
    "    # image = np.array(Image.open(dir_name+img)).reshape((784,))\n",
    "    image = image.tolist()\n",
    "    testset.append(image)\n",
    "testset = np.array(testset)\n",
    "test = pd.DataFrame(testset)\n",
    "test = test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "private_set = []\n",
    "dir_name = '../private_test_dataset/data/'\n",
    "lists = sorted(os.listdir(dir_name))\n",
    "for idx, img in enumerate(lists):\n",
    "    image_gray = cv2.imread(dir_name+img, cv2.IMREAD_GRAYSCALE)\n",
    "    image = np.array(image_gray.reshape((784,)))\n",
    "    # image = np.array(Image.open(dir_name+img)).reshape((784,))\n",
    "    image = image.tolist()\n",
    "    private_set.append(image)\n",
    "private_set = np.array(private_set)\n",
    "private = pd.DataFrame(private_set)\n",
    "private = private/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KWjNSFKVe7lT",
    "outputId": "71860795-76b6-4eee-f6ef-2ff254872eb1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120000, 785)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pPJvXgI0e8Rw",
    "outputId": "4f2e9bc5-fc9e-4ec5-d8a0-a48a97b338a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 784)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "private.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "xy95owsr3q2i"
   },
   "outputs": [],
   "source": [
    "df_train = train.copy()\n",
    "df_test = test.copy()\n",
    "df_private = private.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "yyYLogAI3q2i"
   },
   "outputs": [],
   "source": [
    "X_train= df_train.drop(['label'],axis = 1)\n",
    "y_train = df_train['label']\n",
    "X_test = df_test\n",
    "X_private = df_private\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_private = X_private.astype('float32')\n",
    "X_train /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "QO0OCJA_eXnl"
   },
   "outputs": [],
   "source": [
    "# X_train과 X_label을 하나의 데이터 프레임으로 합침\n",
    "df_train = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "# 데이터 프레임을 섞음\n",
    "df_train = df_train.sample(frac=1, random_state=42)\n",
    "\n",
    "# 섞인 데이터 프레임에서 훈련 데이터와 레이블을 다시 분리\n",
    "X_train = df_train.drop(['label'], axis=1)\n",
    "y_train = df_train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "fVfeVhm5PI7y"
   },
   "outputs": [],
   "source": [
    "def apply_hog(images):\n",
    "    result = []\n",
    "    for image in images:\n",
    "        hog_features = hog(image, orientations=6, pixels_per_cell=(3, 3),\n",
    "                        cells_per_block=(2, 2), block_norm='L2')\n",
    "        result.append(hog_features)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jdm1cfuAT-wS",
    "outputId": "1df3b098-5f5f-47fb-b737-ca8bfadcbad5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120000, 784)\n",
      "(10000, 784)\n",
      "(15000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_private.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "w93Yskv5UyNr"
   },
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_train = X_train.reshape(-1, 28, 28)\n",
    "X_test = np.array(X_test)\n",
    "X_test = X_test.reshape(-1, 28, 28)\n",
    "X_private = np.array(X_private)\n",
    "X_private = X_private.reshape(-1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s_NWdV_kVOLk",
    "outputId": "9b9f02de-0349-415e-ad15-4d18d74df552"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(15000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_private.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "3iqziXcrPL4Y"
   },
   "outputs": [],
   "source": [
    "X_train_hog = apply_hog(X_train)\n",
    "X_test_hog = apply_hog(X_test)\n",
    "X_private_hog = apply_hog(X_private)\n",
    "X_train_hog = np.array(X_train_hog)\n",
    "X_test_hog = np.array(X_test_hog)\n",
    "X_private_hog = np.array(X_private_hog)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AE7ds0A4Vlko",
    "outputId": "8f63bd56-edd8-4f8f-d4cc-ba891339efc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOG 특성을 적용한 X_train의 형태:  (120000, 1536)\n",
      "HOG 특성을 적용한 X_test의 형태:  (10000, 1536)\n",
      "HOG 특성을 적용한 X_private의 형태:  (15000, 1536)\n"
     ]
    }
   ],
   "source": [
    "print(\"HOG 특성을 적용한 X_train의 형태: \", np.array(X_train_hog).shape)\n",
    "print(\"HOG 특성을 적용한 X_test의 형태: \", np.array(X_test_hog).shape)\n",
    "print(\"HOG 특성을 적용한 X_private의 형태: \", np.array(X_private_hog).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UjPSuUvoyAzc"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "UBqdMEFvpFEj"
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=466, random_state=45)\n",
    "pca.fit(X_train_hog)\n",
    "X_train_pca = pca.transform(X_train_hog)\n",
    "X_test_pca = pca.transform(X_test_hog)\n",
    "X_private_pca = pca.transform(X_private_hog)\n",
    "\n",
    "X_train_PCA1 = pd.DataFrame(X_train_pca)\n",
    "X_test_PCA1 = pd.DataFrame(X_test_pca)\n",
    "X_private_PCA1 = pd.DataFrame(X_private_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "iH2iv21bpI_Y",
    "outputId": "07316595-8ae4-4566-b1f2-dd24e2c45987"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=8, random_state=45)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=8, random_state=45)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=8, random_state=45)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_c = 8\n",
    "svc = SVC(gamma='scale',kernel='rbf',C=optimal_c, random_state=45)\n",
    "svc.fit(X_train_PCA1,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "hAhl7pHdpo5l"
   },
   "outputs": [],
   "source": [
    "svc_pred = svc.predict(X_test_PCA1)\n",
    "svc_private = svc.predict(X_private_PCA1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "5bGUyp3Zra_L"
   },
   "outputs": [],
   "source": [
    "f= open(\"testResult_public.txt\",\"w+\")\n",
    "for idx, y in enumerate(svc_pred):\n",
    "    num_str = str(idx).zfill(5)\n",
    "    f.write(num_str + \" \" + str(int(y)) + \"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_private= open(\"testResult_private.txt\",\"w+\")\n",
    "for idx_private, y_private in enumerate(svc_private):\n",
    "    img_num_private = str(idx_private).zfill(5)\n",
    "    f_private.write(img_num_private + \" \" + str(int(y_private)) + \"\\n\")\n",
    "f_private.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test mAP (public test) : 0.8597482817130709\n",
      "| Class         | AP            |\n",
      "|---------------|---------------|\n",
      "| T-shirt/top   | 0.79          |\n",
      "| Trouser       | 0.98          |\n",
      "| Pullover      | 0.79          |\n",
      "| Dress         | 0.83          |\n",
      "| Coat          | 0.77          |\n",
      "| Sandal        | 0.98          |\n",
      "| Shirt         | 0.64          |\n",
      "| Sneaker       | 0.92          |\n",
      "| Bag           | 0.97          |\n",
      "| Ankle boot    | 0.93          |\n",
      "| mAP           | 0.86          |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from sklearn.metrics import auc\n",
    "from collections import Counter\n",
    "\n",
    "testResult_path = 'testResult_public.txt'\n",
    "label_path = '../mAP/label.txt'\n",
    "\n",
    "# pred에 해당하는 testResult.txt 파일 읽어오는 부분입니다.\n",
    "with open(testResult_path, 'r') as file1:\n",
    "    preds = file1.readlines()\n",
    "\n",
    "# 정답에 해당하는 label.txt 파일 읽어오는 부분입니다.\n",
    "with open(label_path, 'r') as file2:\n",
    "    labels = file2.readlines()\n",
    "    \n",
    "\n",
    "# pred와 label의 클래스값만 리스트로 변환하는 부분입니다.\n",
    "p = np.array([pred.strip().split()[1] for pred in preds])\n",
    "l = np.array([label.strip().split()[1] for label in labels])\n",
    "\n",
    "# pred의 클래스 개수를 count하는 부분입니다.\n",
    "predict_label_count_dict = Counter(p)\n",
    "predict_label_count_dict = dict(sorted(predict_label_count_dict.items()))\n",
    "\n",
    "## mAP 계산하는 부분입니다.\n",
    "AP = []\n",
    "num_class = 10\n",
    "\n",
    "# 모든 클래스에 대해 반복\n",
    "for c, freq in predict_label_count_dict.items() :\n",
    "    TP = 0\n",
    "    FN = 0\n",
    "\n",
    "    temp_precision = []\n",
    "    temp_recall = []\n",
    "    \n",
    "    for i in range(len(p)):\n",
    "        # TP, FN 계산\n",
    "        if l[i] == c and p[i] == c :\n",
    "            TP += 1\n",
    "        elif l[i] != c and p[i] == c :\n",
    "            FN += 1\n",
    "        \n",
    "        # preciison, recall 계산            \n",
    "        if TP+FN != 0: \n",
    "            temp_precision.append(TP/(TP+FN))\n",
    "            temp_recall.append(TP/freq)\n",
    "\n",
    "    # AP 배열에 클래스 각각의 AP value 저장\n",
    "    # auc : preciison-recall curve의 면적 구해줌\n",
    "    AP.append(auc(temp_recall, temp_precision))\n",
    "\n",
    "mAP = sum(AP) / num_class\n",
    "\n",
    "# 각각의 클래스에 대한 AP와 mAP의 Table 출력 부분입니다.\n",
    "class_name = ['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle boot']\n",
    "table = \"| {:<13} | {:<13} |\\n\".format(\"Class\", \"AP\") + \"|---------------|---------------|\\n\"\n",
    "\n",
    "for c_name, ap in zip(class_name, AP):\n",
    "    table += \"| {:<13} | {:<13.2f} |\\n\".format(c_name, ap)\n",
    "\n",
    "table += \"| {:<13} | {:<13.2f} |\\n\".format(\"mAP\", mAP)\n",
    "test_mAP = mAP\n",
    "print(\"Test mAP (public test) : {}\".format(test_mAP))\n",
    "print(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
