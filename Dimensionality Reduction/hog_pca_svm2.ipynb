{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "99IcNqG63q2f"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import ensemble\n",
    "from xgboost import XGBClassifier\n",
    "import time\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "emy5HT1T3q2h"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XLy3i9aa3q2i",
    "outputId": "5028f112-f62a-450b-b3ac-1f48356b36cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train = pd.read_csv('../fashionmnist/fashion-mnist_train.csv')\n",
    "# test = pd.read_csv('../public_test_dataset/data')\n",
    "train.isnull().any().sum()\n",
    "# test.isnull().any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "testset = []\n",
    "dir_name = '../public_test_dataset/data/'\n",
    "lists = sorted(os.listdir(dir_name))\n",
    "for idx, img in enumerate(lists):\n",
    "    image_gray = cv2.imread(dir_name+img, cv2.IMREAD_GRAYSCALE)\n",
    "    image = np.array(image_gray.reshape((784,)))\n",
    "    # image = np.array(Image.open(dir_name+img)).reshape((784,))\n",
    "    image = image.tolist()\n",
    "    testset.append(image)\n",
    "testset = np.array(testset)\n",
    "test = pd.DataFrame(testset)\n",
    "test = test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KWjNSFKVe7lT",
    "outputId": "71860795-76b6-4eee-f6ef-2ff254872eb1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 785)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pPJvXgI0e8Rw",
    "outputId": "4f2e9bc5-fc9e-4ec5-d8a0-a48a97b338a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "xy95owsr3q2i"
   },
   "outputs": [],
   "source": [
    "df_train = train.copy()\n",
    "df_test = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "yyYLogAI3q2i"
   },
   "outputs": [],
   "source": [
    "X_train= df_train.drop(['label'],axis = 1)\n",
    "y_train = df_train['label']\n",
    "X_test = df_test\n",
    "# y_test = df_test.drop(['label'],axis = 1)\n",
    "# y_label = df_test['label']\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255.0\n",
    "# y_test /=255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "QO0OCJA_eXnl"
   },
   "outputs": [],
   "source": [
    "# X_train과 X_label을 하나의 데이터 프레임으로 합침\n",
    "df_train = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "# 데이터 프레임을 섞음\n",
    "df_train = df_train.sample(frac=1, random_state=42)\n",
    "\n",
    "# 섞인 데이터 프레임에서 훈련 데이터와 레이블을 다시 분리\n",
    "X_train = df_train.drop(['label'], axis=1)\n",
    "y_train = df_train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "fVfeVhm5PI7y"
   },
   "outputs": [],
   "source": [
    "from skimage.feature import hog\n",
    "def apply_hog(images):\n",
    "    result = []\n",
    "    for image in images:\n",
    "        hog_features = hog(image, orientations=9, pixels_per_cell=(4, 4),\n",
    "                        cells_per_block=(2, 2), block_norm='L2')\n",
    "        result.append(hog_features)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jdm1cfuAT-wS",
    "outputId": "1df3b098-5f5f-47fb-b737-ca8bfadcbad5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "w93Yskv5UyNr"
   },
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_train = X_train.reshape(-1, 28, 28)\n",
    "X_test = np.array(X_test)\n",
    "X_test = X_test.reshape(-1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s_NWdV_kVOLk",
    "outputId": "9b9f02de-0349-415e-ad15-4d18d74df552"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "3iqziXcrPL4Y"
   },
   "outputs": [],
   "source": [
    "X_train_hog = apply_hog(X_train)\n",
    "X_test_hog = apply_hog(X_test)\n",
    "X_train_hog = np.array(X_train_hog)\n",
    "X_test_hog = np.array(X_test_hog)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AE7ds0A4Vlko",
    "outputId": "8f63bd56-edd8-4f8f-d4cc-ba891339efc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOG 특성을 적용한 X_train의 형태:  (60000, 1296)\n",
      "HOG 특성을 적용한 X_test의 형태:  (10000, 1296)\n"
     ]
    }
   ],
   "source": [
    "print(\"HOG 특성을 적용한 X_train의 형태: \", np.array(X_train_hog).shape)\n",
    "print(\"HOG 특성을 적용한 X_test의 형태: \", np.array(X_test_hog).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "id": "0w0PlJwpVv8n",
    "outputId": "5ff4e1e7-3864-4341-b3f6-a8826e0b05cb"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "hog() got an unexpected keyword argument 'multichannel'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/sykim/Desktop/2023-2/ML/Project/codes/hog_pca_svm.ipynb Cell 16\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sykim/Desktop/2023-2/ML/Project/codes/hog_pca_svm.ipynb#X22sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# 첫 번째 이미지의 HOG 특성 계산 및 시각화\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sykim/Desktop/2023-2/ML/Project/codes/hog_pca_svm.ipynb#X22sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m image \u001b[39m=\u001b[39m X_train[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mreshape((\u001b[39m28\u001b[39m, \u001b[39m28\u001b[39m))\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/sykim/Desktop/2023-2/ML/Project/codes/hog_pca_svm.ipynb#X22sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m hog_features, hog_image \u001b[39m=\u001b[39m hog(image, orientations\u001b[39m=\u001b[39;49m\u001b[39m8\u001b[39;49m, pixels_per_cell\u001b[39m=\u001b[39;49m(\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sykim/Desktop/2023-2/ML/Project/codes/hog_pca_svm.ipynb#X22sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                               cells_per_block\u001b[39m=\u001b[39;49m(\u001b[39m2\u001b[39;49m, \u001b[39m2\u001b[39;49m), visualize\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, multichannel\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sykim/Desktop/2023-2/ML/Project/codes/hog_pca_svm.ipynb#X22sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# 원본 이미지와 HOG 특성 이미지를 출력\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sykim/Desktop/2023-2/ML/Project/codes/hog_pca_svm.ipynb#X22sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m fig, (ax1, ax2) \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, figsize\u001b[39m=\u001b[39m(\u001b[39m8\u001b[39m, \u001b[39m4\u001b[39m), sharex\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, sharey\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.9/site-packages/skimage/_shared/utils.py:316\u001b[0m, in \u001b[0;36mchannel_as_last_axis.__call__.<locals>.fixed_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m channel_axis \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mchannel_axis\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    315\u001b[0m \u001b[39mif\u001b[39;00m channel_axis \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 316\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    318\u001b[0m \u001b[39m# TODO: convert scalars to a tuple in anticipation of eventually\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[39m#       supporting a tuple of channel axes. Right now, only an\u001b[39;00m\n\u001b[1;32m    320\u001b[0m \u001b[39m#       integer or a single-element tuple is supported, though.\u001b[39;00m\n\u001b[1;32m    321\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39misscalar(channel_axis):\n",
      "\u001b[0;31mTypeError\u001b[0m: hog() got an unexpected keyword argument 'multichannel'"
     ]
    }
   ],
   "source": [
    "from skimage.io import imshow\n",
    "from skimage import exposure\n",
    "# 첫 번째 이미지의 HOG 특성 계산 및 시각화\n",
    "image = X_train[0].reshape((28, 28))\n",
    "hog_features, hog_image = hog(image, orientations=8, pixels_per_cell=(1, 1),\n",
    "                              cells_per_block=(2, 2), visualize=True, multichannel=False)\n",
    "\n",
    "# 원본 이미지와 HOG 특성 이미지를 출력\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4), sharex=True, sharey=True)\n",
    "\n",
    "ax1.axis('off')\n",
    "ax1.imshow(image, cmap=plt.cm.gray)\n",
    "ax1.set_title('Input image')\n",
    "\n",
    "# Rescale histogram for better display\n",
    "hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 10))\n",
    "\n",
    "ax2.axis('off')\n",
    "ax2.imshow(hog_image_rescaled, cmap=plt.cm.gray)\n",
    "ax2.set_title('Histogram of Oriented Gradients')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UjPSuUvoyAzc"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "UBqdMEFvpFEj"
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=250)\n",
    "pca.fit(X_train_hog)\n",
    "X_train_pca = pca.transform(X_train_hog)\n",
    "X_test_pca = pca.transform(X_test_hog)\n",
    "\n",
    "X_train_PCA1 = pd.DataFrame(X_train_pca)\n",
    "X_test_PCA1 = pd.DataFrame(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "iH2iv21bpI_Y",
    "outputId": "07316595-8ae4-4566-b1f2-dd24e2c45987"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=8)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=8)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_c = 8\n",
    "svc = SVC(gamma='scale',kernel='rbf',C=optimal_c )\n",
    "svc.fit(X_train_PCA1,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "hAhl7pHdpo5l"
   },
   "outputs": [],
   "source": [
    "svc_train = svc.predict(X_train_PCA1)\n",
    "svc_pred = svc.predict(X_test_PCA1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5bGUyp3Zra_L"
   },
   "outputs": [],
   "source": [
    "# pred = model_load.predict(test)\n",
    "f= open(\"../testResults/testResult_public_hog_n400_c8.txt\",\"w+\")\n",
    "for idx, y in enumerate(svc_pred):\n",
    "    num_str = str(idx).zfill(5)\n",
    "    f.write(num_str + \" \" + str(int(y)) + \"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from sklearn.metrics import auc\n",
    "from collections import Counter\n",
    "\n",
    "# testResult_path = sys.argv[1]\n",
    "# label_path = sys.argv[2]\n",
    "\n",
    "testResult_path = '../testResults/testResult_public_hog_n400_c8.txt'\n",
    "label_path = '../mAP/label.txt'\n",
    "\n",
    "# pred에 해당하는 testResult.txt 파일 읽어오는 부분입니다.\n",
    "with open(testResult_path, 'r') as file1:\n",
    "    preds = file1.readlines()\n",
    "\n",
    "# 정답에 해당하는 label.txt 파일 읽어오는 부분입니다.\n",
    "with open(label_path, 'r') as file2:\n",
    "    labels = file2.readlines()\n",
    "    \n",
    "\n",
    "# pred와 label의 클래스값만 리스트로 변환하는 부분입니다.\n",
    "p = np.array([pred.strip().split()[1] for pred in preds])\n",
    "l = np.array([label.strip().split()[1] for label in labels])\n",
    "\n",
    "# pred의 클래스 개수를 count하는 부분입니다.\n",
    "predict_label_count_dict = Counter(p)\n",
    "predict_label_count_dict = dict(sorted(predict_label_count_dict.items()))\n",
    "\n",
    "## mAP 계산하는 부분입니다.\n",
    "AP = []\n",
    "num_class = 10\n",
    "\n",
    "# 모든 클래스에 대해 반복\n",
    "for c, freq in predict_label_count_dict.items() :\n",
    "    TP = 0\n",
    "    FN = 0\n",
    "\n",
    "    temp_precision = []\n",
    "    temp_recall = []\n",
    "    \n",
    "    for i in range(len(p)):\n",
    "        # TP, FN 계산\n",
    "        if l[i] == c and p[i] == c :\n",
    "            TP += 1\n",
    "        elif l[i] != c and p[i] == c :\n",
    "            FN += 1\n",
    "        \n",
    "        # preciison, recall 계산            \n",
    "        if TP+FN != 0: \n",
    "            temp_precision.append(TP/(TP+FN))\n",
    "            temp_recall.append(TP/freq)\n",
    "\n",
    "    # AP 배열에 클래스 각각의 AP value 저장\n",
    "    # auc : preciison-recall curve의 면적 구해줌\n",
    "    print(\"TP :\", TP)\n",
    "    print(\"FN :\", FN)\n",
    "    # print(temp_precision)\n",
    "    # print(temp_recall)\n",
    "    AP.append(auc(temp_recall, temp_precision))\n",
    "\n",
    "mAP = sum(AP) / num_class\n",
    "\n",
    "# 각각의 클래스에 대한 AP와 mAP의 Table 출력 부분입니다.\n",
    "class_name = ['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle boot']\n",
    "table = \"| {:<13} | {:<13} |\\n\".format(\"Class\", \"AP\") + \"|---------------|---------------|\\n\"\n",
    "\n",
    "for c_name, ap in zip(class_name, AP):\n",
    "    table += \"| {:<13} | {:<13.2f} |\\n\".format(c_name, ap)\n",
    "\n",
    "table += \"| {:<13} | {:<13.2f} |\\n\".format(\"mAP\", mAP)\n",
    "test_mAP = mAP\n",
    "print(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc\n",
    "from collections import Counter\n",
    "def calculate_mAP(preds,label):\n",
    "    ## mAP calculation\n",
    "    AP = []\n",
    "    num_class = 10\n",
    "    predict_label_count_dict = Counter(preds)\n",
    "    predict_label_count_dict = dict(sorted(predict_label_count_dict.items()))\n",
    "\n",
    "    # For each class\n",
    "    for c, freq in predict_label_count_dict.items() :\n",
    "        TP = 0\n",
    "        FN = 0\n",
    "\n",
    "        temp_precision = []\n",
    "        temp_recall = []\n",
    "\n",
    "        for i in range(len(preds)):\n",
    "            # Calculate TP and FN\n",
    "            if label[i] == c and preds[i] == c :\n",
    "                TP += 1\n",
    "            elif label[i] != c and preds[i] == c :\n",
    "                FN += 1\n",
    "\n",
    "            # Calculate precision and recall\n",
    "            if TP+FN != 0:\n",
    "                temp_precision.append(TP/(TP+FN))\n",
    "                temp_recall.append(TP/freq)\n",
    "\n",
    "        # Save the AP value of each class to AP array\n",
    "        AP.append(auc(temp_recall, temp_precision))\n",
    "\n",
    "    # Calculate mAP\n",
    "    mAP = sum(AP) / num_class\n",
    "\n",
    "    return mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9EgZDJ1YpzEJ",
    "outputId": "e09c4e5c-4d6c-4fad-ab69-40e4bec2e928"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Map score: 0.9985790382150592\n",
      "Test Map score: 0.8514137160302695\n"
     ]
    }
   ],
   "source": [
    "# train_acc = metrics.accuracy_score(y_train,svc_train)\n",
    "map_train = calculate_mAP(svc_train,y_train)\n",
    "print(\"Train Map score: {}\".format(map_train))\n",
    "print(\"Test Map score: {}\".format(test_mAP))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
