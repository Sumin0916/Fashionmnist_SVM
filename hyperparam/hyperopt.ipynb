{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "UT1HbnkBnjtY",
    "outputId": "c2bb63f6-f5ea-45f7-afba-23026589de9d"
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from hyperopt import STATUS_OK, Trials, hp, space_eval, tpe, fmin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc\n",
    "from collections import Counter\n",
    "def calculate_mAP(preds,label):\n",
    "    ## mAP calculation\n",
    "    AP = []\n",
    "    num_class = 10\n",
    "    predict_label_count_dict = Counter(preds)\n",
    "    predict_label_count_dict = dict(sorted(predict_label_count_dict.items()))\n",
    "\n",
    "    # For each class\n",
    "    for c, freq in predict_label_count_dict.items() :\n",
    "        TP = 0\n",
    "        FN = 0\n",
    "\n",
    "        temp_precision = []\n",
    "        temp_recall = []\n",
    "\n",
    "        for i in range(len(preds)):\n",
    "            # Calculate TP and FN\n",
    "            if label[i] == c and preds[i] == c :\n",
    "                TP += 1\n",
    "\n",
    "            elif label[i] != c and preds[i] == c :\n",
    "                FN += 1\n",
    "\n",
    "            # Calculate precision and recall\n",
    "            if TP+FN != 0:\n",
    "                temp_precision.append(TP/(TP+FN))\n",
    "                temp_recall.append(TP/freq)\n",
    "\n",
    "        # Save the AP value of each class to AP array\n",
    "        AP.append(auc(temp_recall, temp_precision))\n",
    "\n",
    "    # Calculate mAP\n",
    "    mAP = sum(AP) / num_class\n",
    "\n",
    "    return mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from hyperopt import STATUS_OK, Trials, hp, space_eval, tpe, fmin\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hyperopt in c:\\users\\poweruser\\miniconda3\\lib\\site-packages (0.2.7)\n",
      "Requirement already satisfied: six in c:\\users\\poweruser\\miniconda3\\lib\\site-packages (from hyperopt) (1.14.0)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\poweruser\\miniconda3\\lib\\site-packages (from hyperopt) (3.0.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\poweruser\\miniconda3\\lib\\site-packages (from hyperopt) (1.24.4)\n",
      "Requirement already satisfied: networkx>=2.2 in c:\\users\\poweruser\\miniconda3\\lib\\site-packages (from hyperopt) (3.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\poweruser\\miniconda3\\lib\\site-packages (from hyperopt) (1.10.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\poweruser\\miniconda3\\lib\\site-packages (from hyperopt) (4.46.0)\n",
      "Requirement already satisfied: py4j in c:\\users\\poweruser\\miniconda3\\lib\\site-packages (from hyperopt) (0.10.9.7)\n",
      "Requirement already satisfied: future in c:\\users\\poweruser\\miniconda3\\lib\\site-packages (from hyperopt) (0.18.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "train = pd.read_csv('all_augmented.csv')\n",
    "test = pd.read_csv('public_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93000, 785)\n",
      "(10000, 785)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = train.copy()\n",
    "df_test = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= df_train.drop(['label'],axis = 1)\n",
    "X_label = df_train['label']\n",
    "y_test = df_test.drop(['label'],axis = 1)\n",
    "y_label = df_test['label']\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "y_test = y_test.astype('float32')\n",
    "X_train /= 255.0\n",
    "y_test /=255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "public_test_label.txt -> y_label\n",
    "필요한 경우에 실행\n",
    "\"\"\"\n",
    "\n",
    "with open('./label.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "series_data = pd.Series([int(line.strip().split()[1]) if line.strip().split()[1].isdigit() else 0 for line in lines], name='label', dtype='int64')\n",
    "y_label = series_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_label = X_label.values # change to array for mAP\n",
    "y_label = y_label.values # change to array for mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K_hoAHVBoMHo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                          | 0/100 [00:00<?, ?trial/s, best loss=?]"
     ]
    }
   ],
   "source": [
    "# 최적화할 파라미터 공간 정의\n",
    "space = {\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.3),\n",
    "    'max_depth': hp.choice('max_depth', range(1, 11)),\n",
    "    'num_leaves': hp.choice('num_leaves', range(2, 256)),\n",
    "    'feature_fraction': hp.uniform('feature_fraction', 0.4, 1.0),\n",
    "    'bagging_fraction': hp.uniform('bagging_fraction', 0.4, 1.0),\n",
    "    'bagging_freq': hp.choice('bagging_freq', range(1, 8)),\n",
    "    'min_child_samples': hp.choice('min_child_samples', range(5, 101)),\n",
    "    'lambda_l1': hp.loguniform('lambda_l1', 1e-8, 10.0),\n",
    "    'lambda_l2': hp.loguniform('lambda_l2', 1e-8, 10.0),\n",
    "    'min_gain_to_split': hp.loguniform('min_gain_to_split', 0.1, 1),\n",
    "    'max_bin': hp.choice('max_bin', range(128, 513)),\n",
    "    'scale_pos_weight': hp.uniform('scale_pos_weight', 1.0, 100.0),\n",
    "}\n",
    "\n",
    "# 최적화할 목표 함수 정의\n",
    "def objective(space):\n",
    "    model = lgb.LGBMClassifier(\n",
    "        learning_rate=space['learning_rate'],\n",
    "        max_depth=int(space['max_depth']),\n",
    "        num_leaves=int(space['num_leaves']),\n",
    "        feature_fraction=space['feature_fraction'],\n",
    "        bagging_fraction=space['bagging_fraction'],\n",
    "        bagging_freq=int(space['bagging_freq']),\n",
    "        min_child_samples=int(space['min_child_samples']),\n",
    "        lambda_l1=space['lambda_l1'],\n",
    "        lambda_l2=space['lambda_l2'],\n",
    "        min_gain_to_split=space['min_gain_to_split'],\n",
    "        max_bin=int(space['max_bin']),\n",
    "        scale_pos_weight=space['scale_pos_weight'],\n",
    "        objective='multiclass',\n",
    "        num_class=10,\n",
    "        random_state=42,\n",
    "        verbosity=-1,\n",
    "        metric='multi_logloss'\n",
    "    )\n",
    "    \n",
    "    pca = PCA(n_components=400)\n",
    "    lgbm_pipe = Pipeline([\n",
    "        ('pca', pca),\n",
    "        ('lgbm', model)\n",
    "    ])\n",
    "    \n",
    "    train_x, valid_x, train_y, valid_y = train_test_split(X_train, X_label, test_size=0.3, stratify=X_label)\n",
    "    \n",
    "    lgbm_pipe.fit(train_x, train_y)\n",
    "    \n",
    "    preds = lgbm_pipe.predict(valid_x)\n",
    "\n",
    "    mAP = calculate_mAP(preds, valid_y)\n",
    "    \n",
    "    return {'loss': -mAP, 'status': STATUS_OK }\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=100,\n",
    "            trials=trials)\n",
    "\n",
    "best_params = space_eval(space, best)\n",
    "\n",
    "print('Best trial: score {}, params {}'.format(-trials.best_trial['result']['loss'], best_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 손실 함수 값 추출\n",
    "losses = [x['result']['loss'] for x in trials.trials]\n",
    "\n",
    "\n",
    "# 손실 함수 값 그래프 그리기\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(losses)\n",
    "plt.title('Loss per trial')\n",
    "plt.xlabel('Trial')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=400)\n",
    "pca.fit(X_train)\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(y_test)\n",
    "\n",
    "X_train_PCA1 = pd.DataFrame(X_train_pca)\n",
    "X_test_PCA1 = pd.DataFrame(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = lgb.LGBMClassifier(**best_params)\n",
    "clf.fit(X_train_pca, X_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_model_train = clf.predict(X_train_PCA1)\n",
    "clf_model_pred = clf.predict(X_test_PCA1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "clf_train_score = accuracy_score(X_label, clf_model_train)\n",
    "clf_pred_score = accuracy_score(y_label, clf_model_pred)\n",
    "\n",
    "print(\"----LGBM----\")\n",
    "print(\"Train Accuracy score: {}\".format(clf_train_score))\n",
    "print(\"Test Accuracy score: {}\".format(clf_pred_score))\n",
    "print(classification_report(y_label, clf_model_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgbm_model_train = lgbm_model.flatten()\n",
    "# lgbm_model_pred = lgbm_model.flatten()\n",
    "map_train = calculate_mAP(clf_model_train,X_label)\n",
    "map_test = calculate_mAP(clf_model_pred,y_label)\n",
    "print(\"Train Map score: {}\".format(map_train))\n",
    "print(\"Test Map score: {}\".format(map_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
